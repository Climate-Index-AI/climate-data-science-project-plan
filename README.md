# Climate Data Science Project Plan

## Project Overview
Climate Index AI is conducting research project. We are looking for a Data Scientist to assist us. The role is part-time, contract based. The pay basis is $25.00 - $35.00 (USD) per hour. To apply for this role, please read the project description, write a brief summary of your approach (15-30min time spent writing) and submit it by Friday, August 9, in the following way:

## Submission Instructions
1. Create a new PRIVATE repository on your GitHub account. Name it as `climate-data-sience-project-proposal`
2. Add your proposal, `proposal.md` with your write-up on how you would approach this project.
3. Invite `tom-mcmillan` and `vitorbarros` to your repo.
4. Email `tom@climateindex.ai`, and `vitor@climateindex.ai` with the subject "Climate Economics Data Science Project Proposal - [your name]" and include a link to your repository.

## Project Description
Convert published research, and research data trails, into deterministic and probabilistic algorithms and imputations relating to climate change and prediction of asset pricing. Encode those algorithms in Python.

Here is an example of a typical research paper. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3792366

## Activities & Deliverables
1. Algorithm Extraction: Extract algorithms from the research, including mathematical formulas, coefficients, and assumptions.
2. Data Cleaning and Preparation: Clean and preprocess the datasets you are supplied to match the requirements of the algorithms.
3. Algorithm Encoding: Encode the extracted algorithms into Python, ensuring they are functional and accurate.
4. Validation and Testing: Validate the algorithms using the provided datasets to ensure they produce the expected results.
5. Documentation: Document each algorithm, including the logic, data requirements, and any assumptions made during the encoding process.

The final deliverable for each research paper is a .py file containing the research's deterministic and probabilistic algorithms (encoded in python), a list and definition of each variable, and a brief documentation of each algos definition, purpose, and useage.

## Success Metrics
1. Accuracy: Algorithms must produce correct and reliable results.
2. Completeness: All relevant aspects of the research paper must be encoded.
3. Clarity: Documentation should be clear, comprehensive, and easy to follow.
4. Usability: Algorithms should be practical and applicable to real-world use cases.

## Data Sources
The data sources include but are not limited to:
- PRISM Climate Group
- National Oceanic and Atmospheric Administration (NOAA)
- Federal Emergency Management Agency (FEMA)
- NCREIF 
- Real Capital Analytics (RCA)
- U.S. Bureau of Economic Analysis (BEA)
- U.S. Census Bureau
- U.S. Securities and Exchange Commission (SEC)
- COMPUSTAT
- S&P GMI
- Kenneth Frenchâ€™s Data Library
- Ivy DB OptionMetrics
- ISS Carbon Risk Ratings
- Morningstar

## Process
The data scientist may work remotely, and asynchronously. We will check in once weekly, for 30 mins, via zoom. We will talk in real time, over slack, to support the work. 
